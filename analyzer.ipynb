{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "input_directory = \"Sources/\"\n",
    "num_pdfs = 20\n",
    "labels = [\"cat1\", \"cat2\", \"cat3\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "y = np.array([i % len(labels) for i in range(num_pdfs)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recibe un texto en español como entrada y realiza lematización de palabras. Utiliza el algoritmo Snowball para el español para lematizar cada palabra del texto y luego devuelve el texto lematizado como una sola cadena de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    snowball = SnowballStemmer('spanish') \n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [snowball.stem(word) for word in words]\n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `load_lexicon` carga el contenido de un archivo de léxico ubicado en la ruta especificada y lo devuelve como una cadena de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(lexicon_file_path):\n",
    "    with open(lexicon_file_path, 'r', encoding='utf-8') as file:\n",
    "        lexicon_text = file.read()\n",
    "    return lexicon_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `is_related_to_lexicon` verifica si el texto contiene al menos una palabra que está presente en el léxico proporcionado como entrada. Retorna `True` si hay palabras en común entre el texto y el léxico, y `False` en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_related_to_lexicon(text, lexicon):\n",
    "    words_in_lexicon = set(lexicon.split())\n",
    "    words_in_text = set(word_tokenize(text))\n",
    "    return len(words_in_text.intersection(words_in_lexicon)) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `load_lemmatized_text` carga el contenido de un archivo de texto lematizado ubicado en la ruta especificada y lo devuelve como una cadena de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lemmatized_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lemmatized_text = file.read()\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `get_most_common_words` recibe una lista de textos lematizados como entrada y devuelve las palabras más comunes presentes en esos textos. Puede especificarse el número de palabras más comunes a obtener (por defecto son 50). Utiliza expresiones regulares para extraer las palabras de los textos y la clase `Counter` para contar la frecuencia de cada palabra. Luego, selecciona las palabras más comunes y las devuelve en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(lemmatized_texts, num_words=50):\n",
    "    words_freq = Counter()\n",
    "    for text in lemmatized_texts:\n",
    "        words_freq.update(re.findall(r'\\w+', text))\n",
    "\n",
    "    most_common_words = [word for word, _ in words_freq.most_common(num_words)]\n",
    "    return most_common_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `calculate_topic_scores` calcula las puntuaciones de los temas en función de las palabras clave proporcionadas. Toma como entrada un texto lematizado y un diccionario que mapea cada tema a una lista de palabras clave asociadas a ese tema. Luego, cuenta la frecuencia de palabras en el texto lematizado y suma las frecuencias de las palabras clave de cada tema para obtener las puntuaciones respectivas. Finalmente, devuelve un diccionario que asigna cada tema a su puntuación correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_scores(lemmatized_text, topic_keywords):\n",
    "    word_freq = Counter(re.findall(r'\\w+', lemmatized_text))\n",
    "    topic_scores = {topic: sum(word_freq[word] for word in keywords) for topic, keywords in topic_keywords.items()}\n",
    "    return topic_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `get_most_common_words` recibe una lista de textos lematizados como entrada y devuelve una lista de las palabras más comunes presentes en esos textos. Puede especificarse el número de palabras más comunes a obtener (por defecto son 50). Utiliza expresiones regulares para extraer las palabras de los textos y la clase `Counter` para contar la frecuencia de cada palabra. Luego, selecciona las palabras más comunes y las devuelve en una lista ordenada por frecuencia descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(lemmatized_texts, num_words=50):\n",
    "    words_freq = Counter()\n",
    "    for text in lemmatized_texts:\n",
    "        words_freq.update(re.findall(r'\\w+', text))\n",
    "\n",
    "    most_common_words = [word for word, _ in words_freq.most_common(num_words)]\n",
    "    return most_common_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `calculate_topic_scores` calcula las puntuaciones de temas basadas en las palabras clave proporcionadas. Toma como entrada un texto lematizado y un diccionario que asocia cada tema con una lista de palabras clave relacionadas a ese tema. Luego, cuenta la frecuencia de las palabras en el texto lematizado y suma las frecuencias de las palabras clave correspondientes a cada tema. Finalmente, devuelve un diccionario que mapea cada tema a su puntuación resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_topic_scores(lemmatized_text, topic_keywords):\n",
    "    word_freq = Counter(re.findall(r'\\w+', lemmatized_text))\n",
    "    topic_scores = {topic: sum(word_freq[word] for word in keywords) for topic, keywords in topic_keywords.items()}\n",
    "    return topic_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `discretize_scores` toma un diccionario de puntuaciones de temas como entrada y devuelve un nuevo diccionario que asigna una etiqueta discreta (Positivo, Neutro o Negativo) a cada documento basado en la puntuación más alta obtenida en los temas. Si la puntuación más alta es mayor a 0, el documento se etiqueta como \"Positivo\"; si es igual a 0, se etiqueta como \"Neutro\"; y si es menor a 0, se etiqueta como \"Negativo\". El resultado final es un diccionario que mapea el número de cada documento a su etiqueta correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_scores(scores):\n",
    "    discretized_scores = {}\n",
    "    for doc_num, doc_scores in enumerate(scores, 1):\n",
    "        max_score_topic = max(doc_scores, key=doc_scores.get)\n",
    "        max_score = doc_scores[max_score_topic]\n",
    "        if max_score > 0:\n",
    "            discretized_scores[f\"Documento {doc_num}\"] = \"Positivo\"\n",
    "        elif max_score == 0:\n",
    "            discretized_scores[f\"Documento {doc_num}\"] = \"Neutro\"\n",
    "        else:\n",
    "            discretized_scores[f\"Documento {doc_num}\"] = \"Negativo\"\n",
    "    return discretized_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `calculate_document_scores` calcula las puntuaciones de temas para una lista de textos lematizados. Toma como entrada una lista de textos lematizados y un diccionario de palabras clave asociadas a cada tema. Utiliza la función `calculate_topic_scores` para obtener las puntuaciones de temas para cada texto lematizado. Luego, retorna una lista que contiene los resultados de las puntuaciones de temas para cada texto lematizado en el mismo orden en el que fueron proporcionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_document_scores(lemmatized_texts, topic_keywords):\n",
    "    document_scores = []\n",
    "    for lemmatized_text in lemmatized_texts:\n",
    "        scores = calculate_topic_scores(lemmatized_text, topic_keywords)\n",
    "        document_scores.append(scores)\n",
    "    return document_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `calculate_average_scores` calcula el promedio de las puntuaciones de temas para cada documento. Toma como entrada una lista de diccionarios que representan las puntuaciones de temas para diferentes documentos. Para cada diccionario de puntuaciones, calcula el promedio de las puntuaciones y lo agrega a una lista. Finalmente, devuelve una lista que contiene los promedios de las puntuaciones de temas para cada documento en el mismo orden en el que fueron proporcionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_scores(document_scores):\n",
    "    average_scores = []\n",
    "    for doc_scores in document_scores:\n",
    "        average_score = sum(doc_scores.values()) / len(doc_scores)\n",
    "        average_scores.append(average_score)\n",
    "    return average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `train_and_evaluate_models` entrena y evalúa dos modelos de aprendizaje (model1 y model2) utilizando datos de entrenamiento y prueba. Primero, entrena model1 con los datos de entrenamiento y luego hace predicciones en los datos de prueba para calcular su precisión (accuracy1). Luego, realiza una validación cruzada con cv pliegues en model2 utilizando los datos de entrenamiento para obtener la precisión promedio (mean_accuracy_model2). Finalmente, devuelve ambas precisiones como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, model1, model2, cv=5):\n",
    "\n",
    "    model1.fit(X_train, y_train)\n",
    "    y_pred1 = model1.predict(X_test)\n",
    "    accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "\n",
    "    scores_model2 = cross_val_score(model2, X_train, y_train, cv=cv)\n",
    "    mean_accuracy_model2 = scores_model2.mean()\n",
    "    return accuracy1, mean_accuracy_model2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `extract_text_from_pdf` extrae el texto de un archivo PDF ubicado en la ruta especificada. Abre el archivo PDF, recorre cada página y concatena el texto extraído de todas las páginas en una sola cadena. Luego, devuelve el texto extraído como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    with open(pdf_file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `load_data` carga texto desde una serie de archivos PDF ubicados en un directorio de entrada especificado. Utiliza la función `extract_text_from_pdf` para extraer el texto de cada PDF y lo almacena en una lista llamada `data`. Luego, el código utiliza una variable `vectorizer` para transformar la lista `data` en una matriz de características `X` mediante algún método de vectorización (por ejemplo, conteo de palabras o TF-IDF). El resultado es la matriz de características `X`, que se puede utilizar para entrenar modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(input_directory, num_pdfs):\n",
    "    data = []\n",
    "    for pdf_number in range(1, num_pdfs + 1):\n",
    "        pdf_file_path = os.path.join(input_directory, f\"{pdf_number}.pdf\")\n",
    "        text = extract_text_from_pdf(pdf_file_path)\n",
    "        if text is not None:\n",
    "            data.append(text)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = \"Sources/\"\n",
    "    output_directory = \"lematizacion\"\n",
    "    lexicon_file = \"lexicon.txt\"\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    lexicon = load_lexicon(lexicon_file)\n",
    "\n",
    "    for pdf_number in range(1, 21): \n",
    "        pdf_file_path = os.path.join(input_directory, f\"{pdf_number}.pdf\")\n",
    "        text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "        if text is not None:  # Validar si el texto es diferente de None\n",
    "            if is_related_to_lexicon(text, lexicon):\n",
    "                lemmatized_text = lemmatize_text(text)\n",
    "\n",
    "                lemmatized_output_file_path = os.path.join(output_directory, f\"lematizacion_{pdf_number}.txt\")\n",
    "                with open(lemmatized_output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(lemmatized_text)\n",
    "\n",
    "    print(\"Se ha finalizado la lematización de los PDFs relacionados con el léxico y se han almacenado los resultados en la carpeta llamada 'lemmatization'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_directory = \"lematizacion\"\n",
    "    \n",
    "    # Obtener los archivos lematizados\n",
    "lemmatized_texts = []\n",
    "for file_name in os.listdir(lemmatization_directory):\n",
    "    file_path = os.path.join(lemmatization_directory, file_name)\n",
    "    lemmatized_text = load_lemmatized_text(file_path)\n",
    "    lemmatized_texts.append(lemmatized_text)\n",
    "\n",
    "    # Obtener las palabras clave para cada tema de las palabras más utilizadas\n",
    "num_keywords_per_topic = 3\n",
    "most_common_words = get_most_common_words(lemmatized_texts)\n",
    "topic_keywords = {\n",
    "    \"Tema 1\": most_common_words[:num_keywords_per_topic],\n",
    "    \"Tema 2\": most_common_words[num_keywords_per_topic:num_keywords_per_topic*2],\n",
    "    \"Tema 3\": most_common_words[num_keywords_per_topic*2:num_keywords_per_topic*3]\n",
    "        \n",
    "}\n",
    "\n",
    "topic_scores_summary = {topic: 0 for topic in topic_keywords}\n",
    "\n",
    "for lemmatized_text in lemmatized_texts:\n",
    "    scores = calculate_topic_scores(lemmatized_text, topic_keywords)\n",
    "\n",
    "    for topic, score in scores.items():\n",
    "        topic_scores_summary[topic] += score\n",
    "\n",
    "print(\"Puntuación acumulada para cada tema:\")\n",
    "for topic, score in topic_scores_summary.items():\n",
    "     print(f\"{topic}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_directory = \"lematizacion\"\n",
    "    \n",
    "    # Obtener los archivos lematizados\n",
    "lemmatized_texts = []\n",
    "for file_name in os.listdir(lemmatization_directory):\n",
    "    file_path = os.path.join(lemmatization_directory, file_name)\n",
    "    lemmatized_text = load_lemmatized_text(file_path)\n",
    "    lemmatized_texts.append(lemmatized_text)\n",
    "\n",
    "    # Obtener las palabras clave para cada tema de las palabras más utilizadas\n",
    "num_keywords_per_topic = 3\n",
    "most_common_words = get_most_common_words(lemmatized_texts)\n",
    "topic_keywords = {\n",
    "    \"Tema 1\": most_common_words[:num_keywords_per_topic],\n",
    "    \"Tema 2\": most_common_words[num_keywords_per_topic:num_keywords_per_topic*2],\n",
    "    \"Tema 3\": most_common_words[num_keywords_per_topic*2:num_keywords_per_topic*3]\n",
    "        \n",
    " }\n",
    "\n",
    "topic_scores_summary = {topic: 0 for topic in topic_keywords}\n",
    "num_files = len(lemmatized_texts)\n",
    "\n",
    "for lemmatized_text in lemmatized_texts:\n",
    "    scores = calculate_topic_scores(lemmatized_text, topic_keywords)\n",
    "\n",
    "    for topic, score in scores.items():\n",
    "        topic_scores_summary[topic] += score / num_files\n",
    "\n",
    "print(\"Puntaje promedio por Tema:\")\n",
    "for topic, score in topic_scores_summary.items():\n",
    "        print(f\"{topic}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_scores = calculate_document_scores(lemmatized_texts, topic_keywords)\n",
    "\n",
    "print(\"Puntaje acumulado de cada documento:\")\n",
    "for doc_num, scores in enumerate(document_scores, 1):\n",
    "    print(f\"Documento {doc_num}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_scores = calculate_document_scores(lemmatized_texts, topic_keywords)\n",
    "\n",
    "\n",
    "average_scores = calculate_average_scores(document_scores)\n",
    "\n",
    "print(\"Puntaje promedio para cada documento:\")\n",
    "for doc_num, avg_score in enumerate(average_scores, 1):\n",
    "    print(f\"Documento {doc_num}: {avg_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_scores = calculate_document_scores(lemmatized_texts, topic_keywords)\n",
    "\n",
    "\n",
    "discretized_scores = discretize_scores(document_scores)\n",
    "\n",
    "print(\"Discretización de los puntajes:\")\n",
    "for doc, category in discretized_scores.items():\n",
    "    print(f\"{doc}: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = MultinomialNB()\n",
    "model2 = RandomForestClassifier()\n",
    "\n",
    "accuracy_test_train, mean_accuracy_cv = train_and_evaluate_models(X_train, X_test, y_train, y_test, model1, model2, cv=5)\n",
    "\n",
    "print(\"Precisión en testing & training:\", accuracy_test_train)\n",
    "print(\"Precisión en cross-validation:\", mean_accuracy_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
